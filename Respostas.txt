1. Conceitos Fundamentais

    1.1. O que é um dado, característica e classe do problema? (Introduz os conceitos básicos)
    1.2. O que é um problema desbalanceado? (Aborda um desafio comum em ML)
    1.3. O que é um vetor de característica? O que ele representa? (Aprofunda o entendimento sobre dados)
    1.4. Você enxerga um vetor de características e classes na sua base de dados (Iris)? (Aplica o conceito ao dataset do exercício)

2. Coleta, Preparação e Divisão de Dados

    2.1. Onde você encontrou o dataset Iris para este exercício?
    2.2. Quais bibliotecas do Python você usou para carregar e analisar o dataset CSV?
    2.3. Quais passos você seguiu para pré-processar os dados?
    2.4. O que são variáveis independentes (X) e dependentes (y) em um dataset?
    2.5. Qual função do scikit-learn você usou para dividir o dataset em conjuntos de treino e teste?
    2.6. Por que existe a base de treino e teste? (Explica a importância da divisão)
    2.7. Qual a proporção de divisão que você utilizou (treino/teste)?

3. Treinamento do Modelo KNN

    3.1. Qual algoritmo de Machine Learning você implementou neste exercício?
    3.2. Qual biblioteca do scikit-learn você usou para implementar o modelo KNN?
    3.3. Como funciona o KNN? O que é o valor de K? (Explora o funcionamento do algoritmo)
    3.4. O que significa "treinar o modelo" em Machine Learning?

4. Avaliação do Modelo

    4.1. Quais métricas você utilizou para avaliar o desempenho do modelo?
    4.2. Quais funções do scikit-learn você usou para gerar o relatório de classificação e a matriz de confusão?
    4.3. O que são as métricas de avaliação (Matriz de Confusão, Precisão, Recall, F1-Score)? Por que elas são importantes? (Detalha as métricas de avaliação)
    4.4. Explique o que cada uma das seguintes métricas representa:
        Precisão
        Recall
        F1-score
    4.5. O que a matriz de confusão nos mostra sobre o desempenho do modelo?

5. Conceitos Gerais

    5.1. Em suas próprias palavras, explique o que é Machine Learning.
    5.2. Qual a diferença entre aprendizado supervisionado e não supervisionado?
    5.3. Por que é importante avaliar o desempenho de um modelo de Machine Learning?

Respostas:
1-
1.1-
Dados - todo tipo de informação que é coletada para algum fim, pode ser desde uma foto, a números de temperatura por exemplo.
Característica (Feature) - é a o dado que por ex o KNN vai usar, como medidas de uma pétala
Classe (Label) - é a categoria a q um dado pertence, por exemplo a característica XX-YY-ZZ-BB pertence a classe FLOR-X
1.2-
Problema desbalanceado é quando uma ou mais classes do dataset tem mais exemplos que outras, por exemplo, um dataset que possui 950 amostras de pessoas saudáveis
e possui apenas 10 de doentes, o modelo pode simplesmente sempre prever que a pessoa esta saudável e mesmo assim ter um alto nível de acurácia, mas não 
conseguiria e falharia em detectar pessoas da classe doente assim, causando o desbalanceamento  
1.3 - 
O vetor de características é exatamente essa linha do meu código:
x_treino, x_prova, y_treino, y_prova = train_test_split(x, y, test_size=0.2, random_state=42)
sendo as duas variáveis X sendo utilizada para armazenar esse vetor, nesse caso, contendo as medidas das pétalas 
1.4 - 
sim, com essa linha de código -> print(x_treino.iloc[0]), podemos acessar a matriz de características que o Pandas organizou com base no dataset e visualizar a primeira linha, que representa um vetor de características.
2-
2.1-
Para o iris utilizei o link  https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data
e para o wine usei  https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data
2.2- 
pandas -> carrega e manipula os dados em forma de DataFrame
sklearn.model_selection.train_test_split -> divide o dataset em conjuntos de treino e teste.
sklearn.neighbors.KNeighborsClassifier-> implementa o algoritmo KNN
sklearn.metrics.classification_report e confusion_matrix -> geram formas de analisar o desempenho do modelo.
2.3-
carregamento do dataset usando pandas:
data = pd.read_csv("iris/iris.data")

renomeando as colunas com nome para melhorar a leitura e o entendimento do codigo:
data.columns = ["comp_sepala", "larg_sepala", "comp_petala", "larg_petala", "especie"]

e agora separando em x as características e no y as classes:
x = data.drop("especie", axis=1)
y = data["especie"]
2.4-
Variáveis dependentes são componentes essenciais em pesquisas e análises de dados. São chamadas de “dependentes” porque seu valor ou comportamento é 
influenciado ou determinado por outras variáveis, denominadas variáveis independentes.
Em uma relação de causa e efeito, as variáveis dependentes representam o efeito, enquanto as variáveis independentes representam as causas ou fatores que podem afetar o valor
ou o comportamento.
A variável independente é aquela que você altera ou examina para determinar seu impacto na variável dependente.
Por exemplo, se você estiver conduzindo um estudo para investigar como a quantidade de luz afeta o crescimento das plantas, a quantidade de luz é a variável independente, pois você está controlando e manipulando a intensidade da luz. O crescimento das plantas (em termos de altura, tamanho das folhas, etc.) seria a variável dependente, pois é o resultado que você está observando.
A diferença entre variáveis dependentes e independentes reside no papel que cada uma desempenha em um estudo ou análise de dados.
2.5-
train_test_split() da biblioteca scikit-learn
x_treino, x_prova, y_treino, y_prova = train_test_split(x, y, test_size=0.2, random_state=19)
test_size=0.2 -> 20% dos dados são usados para teste, e 80% para treino, um valor muito comum 
random_state=19 -> garante que a divisão seja sempre a mesma
2.6-
Dividimos o dataset em treino e teste para garantir que o modelo consiga generalizar para novos dados e não apenas memorizar os exemplos vistos durante o treinamento,
se usássemos todos os dados apenas para treino, não teríamos como saber se o modelo realmente aprendeu os padrões do problema ou apenas decorou os exemplos. Isso poderia levar ao overfitting, que ocorre quando o modelo se ajusta tão bem aos dados de treino que tem dificuldade em fazer previsões corretas para novos dados, ficando viciado com os dados de treino
2.7-
80% - 20%
3-
3.1-
KNN, é um algoritmo de aprendizado supervisionado baseado na ideia de encontrar os K vizinhos mais próximos para classificar um novo dado.
3.2-
KNeighborsClassifier da biblioteca scikit-learn
permite criar e treinar um modelo KNN com diferentes configurações, como o número de vizinhos e o peso das distâncias
3.3-
ele calcula a distância entre esse novo dado e todos os outros dados do conjunto de treino, na forma que eu implementei no código, ele pega os 3 pontos mais próximos, e quanto mais perto, maior o peso, o valor dele  - > modelo = KNeighborsClassifier(n_neighbors=3, weights='distance')
3.4 - 
significa ajustar seus parâmetros com base nos dados de treino para que ele aprenda a fazer previsões
4-
4.1-
Precisão, recall , F1-score e matriz de confusão
4.2- 
classification_report(y_prova, modelo.predict(x_prova)) - >gera um relatório com Precisão, Recall e F1-score.
confusion_matrix(y_prova, modelo.predict(x_prova)) -> gera a matriz de confusão, mostrando acertos e erros do modelo.
4.3-
Matriz de Confusão - Mostra a quantidade de previsões corretas e incorretas em cada classe.
Precisão - Mede a taxa de acertos entre as previsões positivas feitas pelo modelo.
Sensibilidade ou Recall - Mede a capacidade do modelo de encontrar todos os casos positivos.
F1-score - Média harmônica entre Precisão e Recall, útil quando há dados desbalanceados.
4.4-
Precisão-quantas previsões positivas realmente pertencem àquela classe p = vp / vp + fp ---- fp =  o modelo diz que alguém está doente, mas na verdade não está 
Sensibilidade- quantas amostras reais de uma classe foram corretamente identificadas s = vp / vp + fn ---- fn = corre quando o modelo diz que alguém NÃO está doente, mas na verdade está
F1-score - é útil quando há desequilíbrio de classes, pois equilibra os erros - f1 = 2 * (p * s / p + s)
4.5 -
Os valores na diagonal principal representam acertos
Os valores fora da diagonal representam erros 
sendo vp fp fp 
      fp vp fp 
      fp fp vp
5 - 
5.1 - 
significa aprendizado de maquina, que faz maquinas aprenderem padrões com entrada de dados sem precisar faz, por exemplo, um if para cada situação, então sem precisar de programação explicita  
5.2- 
Supervisionado - O modelo aprende a partir de dados rotulados (ou seja, já sabemos a resposta certa) 
EX: classificar e-mails como spam ou não spam
Não Supervisionado - O modelo não recebe rótulos, apenas os dados brutos, e precisa descobrir padrões sozinho
EX: o recomendar do youtube, ele faz recomendação de vídeos baseado em pessoas que tem os gosto parecidos 
5.3 -
é essencial para garantir que ele realmente aprendeu os padrões corretos, e não apenas decorou os dados de treino, mais conhecido como overfitting




Referencias para os codigos, respostas e slides:
https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier 
https://pt.khanacademy.org/math/pre-algebra/pre-algebra-equations-expressions/pre-algebra-dependent-independent/a/dependent-and-independent-variables-review 
https://didatica.tech/scikit-learn-na-pratica-codigos-uteis-e-comandos-essenciais/ 
https://didatica.tech/dados-de-treino-e-teste/ 
https://www.youtube.com/watch?v=IHAb3NHDahU 
https://www.youtube.com/watch?v=N2TT2Q83abc 
https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html 
https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation 
https://scikit-learn.org/stable/modules/neighbors.html#classification 
https://medium.com/@nirajan.acharya777/understanding-precision-recall-f1-score-and-support-in-machine-learning-evaluation-7ec935e8512e 
https://gist.github.com/tijptjik/9408623 
https://github.com/GustavoAkyama/wine-quality-predict 
https://www.youtube.com/watch?v=FZqMCgCbo3U 
https://blog.mettzer.com/variaveis-dependentes-e-independentes/ 
https://www.ibm.com/br-pt/topics/machine-learning
https://www.sas.com/pt_br/insights/analytics/machine-learning.html
https://medium.com/data-hackers/principais-m%C3%A9tricas-de-classifica%C3%A7%C3%A3o-de-modelos-em-machine-learning-94eeb4b40ea9
https://www.datacamp.com/tutorial/precision-recall-curve-tutorial
